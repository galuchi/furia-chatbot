# üêÜ FURIA Chatbot

Um chatbot interativo desenvolvido para melhorar a experi√™ncia dos f√£s do time de CS da FURIA, fornecendo respostas inteligentes e contextualizadas sobre o time, jogadores e partidas. A solu√ß√£o combina intelig√™ncia artificial com uma interface web moderna.

## üöÄ Tecnologias Utilizadas

### Front-end
- **Next.js (React)** ‚Äì Framework para cria√ß√£o da interface web.
- **Tailwind CSS** ‚Äì Estiliza√ß√£o r√°pida e responsiva.
- **Vercel** ‚Äì Deploy da aplica√ß√£o front-end.

### Back-end
- **Python (Flask)** ‚Äì API para integra√ß√£o com modelos de linguagem.
- **OpenAI API (GPT-4.1-mini)** ‚Äì Gera√ß√£o das respostas do chatbot.
- **Render** ‚Äì Hospedagem do back-end.

### Outros
- **Environment Variables** ‚Äì Utilizadas para armazenar chaves de API de forma segura (`NEXT_PUBLIC_BACKEND_URL`, `OPENAI_API_KEY`, etc).

---

## üí° Funcionalidade

O chatbot responde perguntas sobre o time da FURIA de forma contextualizada, usando um modelo da OpenAI. Os dados e a personalidade do bot podem ser ajustados no back-end via prompt.

---

## üîé Acesse em

https://furia-chatbot-gray.vercel.app

## ‚öôÔ∏è Como rodar localmente

### 1. Clonar o reposit√≥rio

```bash
git clone https://github.com/seu-usuario/furia-chatbot.git
cd furia-chatbot
```

### 2. Configurar o ambiente

Substitua algumas linhas de c√≥digo para o programa funcionar em ambiente local

- Em **page.tsx** (linha 47)

```javascript
//Troque
const response = await fetch(`${process.env.NEXT_PUBLIC_BACKEND_URL}/chat`, {

//Por
const response = await fetch("http://localhost:8000/chat", {   //Certifique-se que essa ser√° sua porta hospedada no backend
```

- Em **main.py** 

```python
//Troque
allow_origins=origins       //Linha 19
//Por
allow_origins=[*]

//Troque
openai.api_key = os.getenv("OPENAI_API_KEY")         //Linha 30
//Por
openai.api_key = "OPENAI_API_KEY"       //Coloque aqui sua chave pr√≥pria para a API da OpenAi
```

Fique √† vontade para alterar e testar outros modelos dispon√≠veis pela OpenAi

### 3. Instalar as depend√™ncias

- Front-end

```bash
# Dentro do diret√≥rio raiz
cd frontend
npm install
```

- Back-end

```bash
# Dentro do diret√≥rio raiz
python3 -m venv venv

source venv/Scripts/activate      ## Para Linux
.\venv\Scripts\Activate           ## Para Windows PowerShell

pip install -r requirements.txt

```

### 4. Rodar o projeto
- **Back-end** (sempre em primeiro)

```bash
# Dentro do diret√≥rio raiz
uvicorn app.main:app
```

Acesse o back-end em http://localhost:8000

- **Front-end** 

```bash
# Em ./frontend
npm run dev
```

Acesse o front-end em http://localhost:3000

